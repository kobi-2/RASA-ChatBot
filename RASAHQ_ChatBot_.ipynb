{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RASAHQ-ChatBot .ipynb",
      "provenance": [],
      "collapsed_sections": [
        "6m3SJ-9GA4B0"
      ],
      "toc_visible": true,
      "mount_file_id": "1oxPo76dBfEQ31C_Q8qocFBqFl9bT7hGA",
      "authorship_tag": "ABX9TyOYaB9Tjf9UfoK3Io3dji3s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kobi-2/RASA-ChatBot/blob/main/RASAHQ_ChatBot_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ra3hkymEpKo"
      },
      "source": [
        "# RASAHQ Simple Chat Assistant\n",
        "[Web Link]() [Github Link](https://github.com/RasaHQ/rasa) <br>\n",
        "\n",
        "Rasa is a chatbot framework for voice or text conversation. It is open source. This framework learns using machine learning and can be an automated assistant for many task and on many platforms!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPJ-Jv3AAqEU"
      },
      "source": [
        "## Setting Up the Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHX76577ukma"
      },
      "source": [
        "'''\n",
        "Getting the latest updates, and versions of python and pip\n",
        "'''\n",
        "\n",
        "!sudo apt update\n",
        "!sudo apt install python3-dev python3-pip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjWA8_1DtkzL"
      },
      "source": [
        "!python3 --version\n",
        "!pip3 --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpVAfIF2AwMS"
      },
      "source": [
        "### [Optional] Setting up a Virtual Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkJlaHlbu20Q"
      },
      "source": [
        "'''\n",
        "Creates virtual environment. This is an optional step. \n",
        "This, however, is recommended because it is safer and cleaner to install packages for special projects in virtual environment rathe than in global system.\n",
        "'''\n",
        "\n",
        "!apt-get install python3.7-dev python3.7-venv   # added this line because without 3.7-venv installation, next comand of venv shows error.\n",
        "!python3 -m venv ./venv\n",
        "!source ./venv/bin/activate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6m3SJ-9GA4B0"
      },
      "source": [
        "## Installing RASA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRqtVahT_OtT"
      },
      "source": [
        "'''\n",
        "Installing the latest pip\n",
        "'''\n",
        "\n",
        "!pip3 install -U pip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0G6CTTPvJNI"
      },
      "source": [
        "'''\n",
        "Installing rasa\n",
        "'''\n",
        "\n",
        "!pip3 install rasa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTZsI19-4HDf"
      },
      "source": [
        "!rasa --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIZLBpafAeQ7"
      },
      "source": [
        "## Initializing RASA, with necessary files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0UK3uh4zdgv"
      },
      "source": [
        "'''\n",
        "Making directory to have all the necessary rasa files together. \n",
        "Moving into rasa directiory so that when we try to initialize it and the prompt asks if we want to save the necessary files in that directory, we can say yes.\n",
        "'''\n",
        "\n",
        "!mkdir rasa\n",
        "%cd rasa/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9I87i7evR-Y",
        "outputId": "3106c5bb-4482-4eff-8197-af607526fdfa"
      },
      "source": [
        "'''\n",
        "This command is a simple do-all command: it basically sets up the assistant.\n",
        "It creates new project, actions, necessary files in the specified directory, \n",
        "and can train given the permission, followed by a chat thread to begin conversation.\n",
        "\n",
        "Here printf passes the answers to the prompts when the command is run. \n",
        "The first prompt is, if you want to save the init files in this present working directory - to which the printf is currently passing '\\n' = yes.\n",
        "The second prompt is, if you want to train the model now, to which the printf is currently passing 'N\\n' = No.\n",
        "There is a third prompt, if you would like to start chat now. \n",
        "\n",
        "Note: If you do not pass the Y/N propmt in the command line with rasa init command, be sure to do so manually when prompted. \n",
        "In google colab, the promp does not show, but instead there is a warning saying your terminal doesn't support cursor position requests (CPR).\n",
        "That means this prompt is waiting for an input.\n",
        "'''\n",
        "\n",
        "!printf '\\nN\\n' | python -m rasa init"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-07 20:24:02.425009: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "\u001b(0lqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqk\u001b(B\n",
            "\u001b(0x\u001b(B Rasa Open Source reports anonymous usage telemetry to help improve the product \u001b(0x\u001b(B\n",
            "\u001b(0x\u001b(B for all its users.                                                             \u001b(0x\u001b(B\n",
            "\u001b(0x\u001b(B                                                                                \u001b(0x\u001b(B\n",
            "\u001b(0x\u001b(B If you'd like to opt-out, you can use `rasa telemetry disable`.                \u001b(0x\u001b(B\n",
            "\u001b(0x\u001b(B To learn more, check out https://rasa.com/docs/rasa/telemetry/telemetry.       \u001b(0x\u001b(B\n",
            "\u001b(0mqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqj\u001b(B\n",
            "2021-04-07 20:24:04.823041: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2021-04-07 20:24:04.873332: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-04-07 20:24:04.873389: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (2ce6b18bca63): /proc/driver/nvidia/version does not exist\n",
            "\u001b[92mWelcome to Rasa! ðŸ¤–\n",
            "\u001b[0m\n",
            "To get started quickly, an initial project will be created.\n",
            "If you need some help, check out the documentation at https://rasa.com/docs/rasa.\n",
            "Now let's start! ðŸ‘‡ðŸ½\n",
            "\n",
            "Warning: Input is not to a terminal (fd=0).\n",
            "\u001b[79Ct\u001b[0m\n",
            "\u001b[79Ct\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[J\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?2004lCreated project directory at '/content/rasa'.\n",
            "\u001b[92mFinished creating project structure.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[J\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?2004l\u001b[92mNo problem ðŸ‘ðŸ¼. You can also train a model later by going to the project directory and running 'rasa train'.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5in2gV7AkUL"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LO010Z5vC0yD"
      },
      "source": [
        "### Customizing the Data:\n",
        "\n",
        "To train on custom data, we need 3 files:\n",
        "1. **nlu.yml** (in the /data/ directory) -> this records the intents (conversation subjects) and their examples.\n",
        "2. **domain.yml** -> this contains possible replies to the intents.\n",
        "3. **stories.yml** (in /data/ directory) -> this contains outlines for stories, which are some example conversation flow. this brings intents from nlu.yml and replies from domain.yml together.\n",
        "\n",
        "There is another file (in /data/ directory) called rules.yml, which specifies rules, such as, the assistant will say goodbye every time the user says goodbye."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuWN7MezRpNv"
      },
      "source": [
        "### Custom scenario:\n",
        "\n",
        "In this github repo, [RASA-ChatBot](https://github.com/kobi-2/RASA-ChatBot), we created a custom RASA ChatBot Data. It acts as a helpdesk for applying to an internship.\n",
        "\n",
        "An example of the conversation:\n",
        "\n",
        "- Hi <br>\n",
        "RASA: Hey, how may I help you?\n",
        "\n",
        "- Do you have any internship? <br>\n",
        "RASA: yes\n",
        "\n",
        "- what company is it? <br>\n",
        "RASA: ABC company limited.\n",
        "\n",
        "- What is the job? <br>\n",
        "RASA: you will be learning and helping to implement various ML tasks in practical real life scenarios.\n",
        "\n",
        "- How can I apply? <br>\n",
        "RASA: you can send your cv at hr@abc.com. Upon that, you will be asked to complete an online form with some simple technical tasks, followed by an interview and another task. That is all! \n",
        "\n",
        "For this, we changed in 4 files: \n",
        "1. nlu.yml  [[github link](https://github.com/kobi-2/RASA-ChatBot/blob/main/rasa/data/nlu.yml)]\n",
        "2. domain.yml  [[github link](https://github.com/kobi-2/RASA-ChatBot/blob/main/rasa/domain.yml)]\n",
        "3. stories.yml [[github link](https://github.com/kobi-2/RASA-ChatBot/blob/main/rasa/data/stories.yml)]\n",
        "4. rules.yml [[github link](https://github.com/kobi-2/RASA-ChatBot/blob/main/rasa/data/rules.yml)]\n",
        "\n",
        "If you want to train on this custom data, run the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vt-b1KW4YJ67",
        "outputId": "48a52c35-3806-4afd-cfa2-6522fa22ac34"
      },
      "source": [
        "'''\n",
        "To train on the custom data from this github repo (https://github.com/kobi-2/RASA-ChatBot), run this cell.\n",
        "It will remove the default nlu.yml, domain.yml, stories.yml, and rules.yml, and download them from the repo.\n",
        "'''\n",
        "\n",
        "# removing default domain.yml and downloading from the github link\n",
        "%cd '/content/rasa/'\n",
        "!rm '/content/rasa/domain.yml'\n",
        "!wget 'https://raw.githubusercontent.com/kobi-2/RASA-ChatBot/main/rasa/domain.yml'\n",
        "\n",
        "# removing the default nlu.yml, stories.yml and rules.yml, and downloading them from the github repo \n",
        "%cd '/content/rasa/data'\n",
        "!rm '/content/rasa/data/nlu.yml'\n",
        "!rm '/content/rasa/data/rules.yml'\n",
        "!rm '/content/rasa/data/stories.yml'\n",
        "\n",
        "!wget 'https://raw.githubusercontent.com/kobi-2/RASA-ChatBot/main/rasa/data/nlu.yml'\n",
        "!wget 'https://raw.githubusercontent.com/kobi-2/RASA-ChatBot/main/rasa/data/rules.yml'\n",
        "!wget 'https://raw.githubusercontent.com/kobi-2/RASA-ChatBot/main/rasa/data/stories.yml'\n",
        "\n",
        "%cd '/content/rasa/'"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/rasa\n",
            "--2021-04-07 22:14:29--  https://raw.githubusercontent.com/kobi-2/RASA-ChatBot/main/rasa/domain.yml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1217 (1.2K) [text/plain]\n",
            "Saving to: â€˜domain.ymlâ€™\n",
            "\n",
            "domain.yml          100%[===================>]   1.19K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-04-07 22:14:29 (48.0 MB/s) - â€˜domain.ymlâ€™ saved [1217/1217]\n",
            "\n",
            "/content/rasa/data\n",
            "--2021-04-07 22:14:29--  https://raw.githubusercontent.com/kobi-2/RASA-ChatBot/main/rasa/data/nlu.yml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2646 (2.6K) [text/plain]\n",
            "Saving to: â€˜nlu.ymlâ€™\n",
            "\n",
            "nlu.yml             100%[===================>]   2.58K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-04-07 22:14:29 (34.4 MB/s) - â€˜nlu.ymlâ€™ saved [2646/2646]\n",
            "\n",
            "--2021-04-07 22:14:30--  https://raw.githubusercontent.com/kobi-2/RASA-ChatBot/main/rasa/data/rules.yml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 748 [text/plain]\n",
            "Saving to: â€˜rules.ymlâ€™\n",
            "\n",
            "rules.yml           100%[===================>]     748  --.-KB/s    in 0s      \n",
            "\n",
            "2021-04-07 22:14:30 (37.8 MB/s) - â€˜rules.ymlâ€™ saved [748/748]\n",
            "\n",
            "--2021-04-07 22:14:30--  https://raw.githubusercontent.com/kobi-2/RASA-ChatBot/main/rasa/data/stories.yml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 907 [text/plain]\n",
            "Saving to: â€˜stories.ymlâ€™\n",
            "\n",
            "stories.yml         100%[===================>]     907  --.-KB/s    in 0s      \n",
            "\n",
            "2021-04-07 22:14:30 (64.4 MB/s) - â€˜stories.ymlâ€™ saved [907/907]\n",
            "\n",
            "/content/rasa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Je-23XzrNa7e",
        "outputId": "3630e599-6a20-4ae0-85e5-7e7f55b99d13"
      },
      "source": [
        "'''\n",
        "To train a model. \n",
        "'''\n",
        "\n",
        "!rasa train"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-07 21:58:03.755260: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-04-07 21:58:06.090336: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2021-04-07 21:58:06.101558: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-04-07 21:58:06.101618: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (2ce6b18bca63): /proc/driver/nvidia/version does not exist\n",
            "\u001b[94mThe configuration for policies and pipeline was chosen automatically. It was written into the config file at 'config.yml'.\u001b[0m\n",
            "2021-04-07 21:58:06 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.model\u001b[0m  - Data (stories) for Core model section changed.\n",
            "\u001b[94mNLU data/configuration did not change. No need to retrain NLU model.\u001b[0m\n",
            "2021-04-07 21:58:07.683809: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-04-07 21:58:07.689742: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2000129999 Hz\n",
            "2021-04-07 21:58:07.689992: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e80c884d80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-04-07 21:58:07.690029: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "\u001b[93m/usr/local/lib/python3.7/dist-packages/rasa/utils/train_utils.py:535: UserWarning: model_confidence is set to `softmax`. It is recommended to try using `model_confidence=linear_norm` to make it easier to tune fallback thresholds.\n",
            "  category=UserWarning,\n",
            "\u001b[0m\u001b[94mTraining Core model...\u001b[0m\n",
            "Processed story blocks: 100% 4/4 [00:00<00:00, 2067.18it/s, # trackers=1]\n",
            "Processed story blocks: 100% 4/4 [00:00<00:00, 624.57it/s, # trackers=4]\n",
            "Processed story blocks: 100% 4/4 [00:00<00:00, 111.69it/s, # trackers=20]\n",
            "Processed story blocks: 100% 4/4 [00:00<00:00, 29.42it/s, # trackers=50]\n",
            "Processed rules: 100% 6/6 [00:00<00:00, 3784.33it/s, # trackers=1]\n",
            "Processed trackers: 100% 4/4 [00:00<00:00, 1343.68it/s, # actions=24]\n",
            "Processed actions: 24it [00:00, 7472.04it/s, # examples=22]\n",
            "Processed trackers: 100% 244/244 [00:02<00:00, 106.63it/s, # actions=64]\n",
            "Epochs: 100% 100/100 [00:13<00:00,  7.69it/s, t_loss=9.84, loss=9.65, acc=0.906]\n",
            "Processed trackers: 100% 6/6 [00:00<00:00, 1317.93it/s, # actions=13]\n",
            "Processed actions: 13it [00:00, 10142.48it/s, # examples=12]\n",
            "Processed trackers: 100% 4/4 [00:00<00:00, 1258.13it/s, # actions=24]\n",
            "Processed trackers: 100% 6/6 [00:00<00:00, 1398.65it/s]\n",
            "Processed trackers: 100% 10/10 [00:00<00:00, 821.80it/s]\n",
            "2021-04-07 21:58:34 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.core.agent\u001b[0m  - Persisted model to '/tmp/tmpytszhm3w/core'\n",
            "\u001b[94mCore model training completed.\u001b[0m\n",
            "\u001b[92mYour Rasa model is trained and saved at '/content/rasa/models/20210407-215834.tar.gz'.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRF8Mw4gAlbz"
      },
      "source": [
        "## Chat"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXgbAFDv3mSf",
        "outputId": "f40d96e1-f48b-483a-d523-afe2b65ee4ba"
      },
      "source": [
        "'''\n",
        "Starts a chat thread with the rasa assistant.\n",
        "'''\n",
        "\n",
        "!rasa shell"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-07 21:59:09.162995: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-04-07 21:59:11.538418: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2021-04-07 21:59:11.550442: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-04-07 21:59:11.550492: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (2ce6b18bca63): /proc/driver/nvidia/version does not exist\n",
            "2021-04-07 21:59:11 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.model\u001b[0m  - Loading model models/20210407-215834.tar.gz...\n",
            "2021-04-07 21:59:13 \u001b[1;30mINFO    \u001b[0m \u001b[34mroot\u001b[0m  - Connecting to channel 'cmdline' which was specified by the '--connector' argument. Any other channels will be ignored. To connect to all given channels, omit the '--connector' argument.\n",
            "2021-04-07 21:59:13 \u001b[1;30mINFO    \u001b[0m \u001b[34mroot\u001b[0m  - Starting Rasa server on http://localhost:5005\n",
            "2021-04-07 21:59:13 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.model\u001b[0m  - Loading model models/20210407-215834.tar.gz...\n",
            "2021-04-07 21:59:14.691110: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-04-07 21:59:14.697018: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2000129999 Hz\n",
            "2021-04-07 21:59:14.697242: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5581832af100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-04-07 21:59:14.697276: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "\u001b[93m/usr/local/lib/python3.7/dist-packages/rasa/utils/train_utils.py:535: UserWarning: model_confidence is set to `softmax`. It is recommended to try using `model_confidence=linear_norm` to make it easier to tune fallback thresholds.\n",
            "  category=UserWarning,\n",
            "\u001b[0m2021-04-07 21:59:35 \u001b[1;30mINFO    \u001b[0m \u001b[34mroot\u001b[0m  - Rasa server is up and running.\n",
            "\u001b[92mBot loaded. Type a message and press enter (use '/stop' to exit): \u001b[0m\n",
            "\u001b[15C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[15D\u001b[J\u001b[0m\u001b[?7h\u001b[?2004l\u001b[?1lWARNING: your terminal doesn't support cursor position requests (CPR).\n",
            "\u001b[0m\n",
            "\u001b[J\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?2004l\u001b[94mHey! How may I help you?\u001b[0m\n",
            "\u001b[15C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[15D\u001b[J\u001b[0m\u001b[?7h\u001b[?2004l\u001b[?1lWARNING: your terminal doesn't support cursor position requests (CPR).\n",
            "\u001b[0m\n",
            "\u001b[J\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?2004l\u001b[94myes\u001b[0m\n",
            "\u001b[15C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[15D\u001b[J\u001b[0m\u001b[?7h\u001b[?2004l\u001b[?1lWARNING: your terminal doesn't support cursor position requests (CPR).\n",
            "\u001b[0m\n",
            "\u001b[J\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?2004l\u001b[94mABC Company Limited\u001b[0m\n",
            "\u001b[15C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[15D\u001b[J\u001b[0m\u001b[?7h\u001b[?2004l\u001b[?1lWARNING: your terminal doesn't support cursor position requests (CPR).\n",
            "\u001b[0m\n",
            "\u001b[J\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?2004l\u001b[94myou will be learning and helping to implement various ML tasks in practical real life scenarios.\u001b[0m\n",
            "\u001b[15C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[15D\u001b[J\u001b[0m\u001b[?7h\u001b[?2004l\u001b[?1lWARNING: your terminal doesn't support cursor position requests (CPR).\n",
            "\u001b[0m\n",
            "\u001b[J\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?2004l\u001b[94myou can send your cv at hr@abc.com. Upon that, you will be asked to complete an online form with some simple technical tasks, followed by an interview and another task. That is all!\u001b[0m\n",
            "\u001b[15C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[15D\u001b[J\u001b[0m\u001b[?7h\u001b[?2004l\u001b[?1lWARNING: your terminal doesn't support cursor position requests (CPR).\n",
            "\u001b[0m\n",
            "\u001b[J\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?2004l\u001b[94mYou're welcome!\u001b[0m\n",
            "\u001b[15C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[15D\u001b[J\u001b[0m\u001b[?7h\u001b[?2004l\u001b[?1lWARNING: your terminal doesn't support cursor position requests (CPR).\n",
            "\u001b[0m\n",
            "\u001b[J\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?2004l\u001b[94mABC Company Limited\u001b[0m\n",
            "\u001b[15C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[15D\u001b[J\u001b[0m\u001b[?7h\u001b[?2004l\u001b[?1lWARNING: your terminal doesn't support cursor position requests (CPR).\n",
            "\u001b[0m\n",
            "\u001b[J\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?2004l\u001b[94myou will be learning and helping to implement various ML tasks in practical real life scenarios.\u001b[0m\n",
            "\u001b[15C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[15D\u001b[J\u001b[0m\u001b[?7h\u001b[?2004l\u001b[?1lWARNING: your terminal doesn't support cursor position requests (CPR).\n",
            "\u001b[0m\n",
            "\u001b[J\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?2004l\u001b[94myou can send your cv at hr@abc.com. Upon that, you will be asked to complete an online form with some simple technical tasks, followed by an interview and another task. That is all!\u001b[0m\n",
            "\u001b[15C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[15D\u001b[J\u001b[0m\u001b[?7h\u001b[?2004l\u001b[?1lWARNING: your terminal doesn't support cursor position requests (CPR).\n",
            "\u001b[0m\n",
            "\u001b[J\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?2004l\u001b[94myou can send your cv at hr@abc.com. Upon that, you will be asked to complete an online form with some simple technical tasks, followed by an interview and another task. That is all!\u001b[0m\n",
            "\u001b[15C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[15D\u001b[J\u001b[0m\u001b[?7h\u001b[?2004l\u001b[?1lWARNING: your terminal doesn't support cursor position requests (CPR).\n",
            "\u001b[0m\n",
            "\u001b[J\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?2004l\u001b[94myou will be learning and helping to implement various ML tasks in practical real life scenarios.\u001b[0m\n",
            "\u001b[15C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[15D\u001b[J\u001b[0m\u001b[?7h\u001b[?2004l\u001b[?1lWARNING: your terminal doesn't support cursor position requests (CPR).\n",
            "\u001b[0m\n",
            "\u001b[J\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?2004l\u001b[94mYou're welcome!\u001b[0m\n",
            "\u001b[15C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[15D\u001b[J\u001b[0m\u001b[?7h\u001b[?2004l\u001b[?1lWARNING: your terminal doesn't support cursor position requests (CPR).\n",
            "\u001b[0m\n",
            "\u001b[J\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?2004l2021-04-07 22:01:14 \u001b[1;30mINFO    \u001b[0m \u001b[34mroot\u001b[0m  - Killing Sanic server now.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}